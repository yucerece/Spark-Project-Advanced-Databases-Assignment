{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45133fbe-7a79-4cee-8dd4-09aa1986d259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9\n",
      "    Uninstalling py4j-0.10.9:\n",
      "      Successfully uninstalled py4j-0.10.9\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyspark-stubs 3.0.0.post3 requires pyspark<3.1.0,>=3.0.0.dev0, but you have pyspark 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed py4j-0.10.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccfaa9c-0b48-4550-9da3-56bd16a6bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark-stubs in /opt/conda/lib/python3.11/site-packages (3.0.0.post3)\n",
      "Collecting pyspark<3.1.0,>=3.0.0.dev0 (from pyspark-stubs)\n",
      "  Using cached pyspark-3.0.3-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9 (from pyspark<3.1.0,>=3.0.0.dev0->pyspark-stubs)\n",
      "  Using cached py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.7\n",
      "    Uninstalling py4j-0.10.9.7:\n",
      "      Successfully uninstalled py4j-0.10.9.7\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.5.0\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark-stubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7025fad3-4092-4a97-8f59-e6a61faef1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf5f5d6-d2ff-414b-a045-b55d800e4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ab90e0-f0d1-4c18-99e7-a88adcb8ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "        .config(\"spark.executor.memory\", \"500mb\") \\\n",
    "        .appName(\"Exercise1\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e6185d-a488-48b7-9e7c-1240bf88acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_table = spark.read.parquet(\"./data/products_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d5a497-9539-4976-8a33-c5db82841bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_table = spark.read.parquet(\"./data/sales_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb06abab-f8e0-4c67-b1e7-9b4af63ccbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers_table = spark.read.parquet(\"./data/sellers_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73692841-6e14-4533-8ae8-ade7e8d07f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders: 75000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of orders: {}\".format(products_table.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10cadd6a-6261-4688-8548-3bf5d36e0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of orders: {}\".format(sellers_table.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d6b6f0c-562d-4f70-9177-a5e3cc9377bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of orders: 994971\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of orders: {}\".format(sales_table.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ab0064-58f3-4a57-a993-3e876ad99cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products sold at least once\n",
      "+--------------------------+\n",
      "|count(DISTINCT product_id)|\n",
      "+--------------------------+\n",
      "|                    988403|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of products sold at least once\")\n",
    "sales_table.agg(countDistinct(col(\"product_id\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4868fb60-3517-4e13-98b1-91aaeab1bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product present in more orders\n",
      "+----------+---+\n",
      "|product_id|cnt|\n",
      "+----------+---+\n",
      "|  28592106|  3|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Product present in more orders\")\n",
    "sales_table.groupBy(col(\"product_id\")).agg(count(\"*\").alias(\"cnt\")).orderBy(col(\"cnt\").desc()).limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5384e78f-b61b-4108-a3b4-35e9bd54be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+\n",
      "|      date|distinct_products_sold|\n",
      "+----------+----------------------+\n",
      "|2020-07-06|                100300|\n",
      "|2020-07-09|                 99946|\n",
      "|2020-07-01|                 99831|\n",
      "|2020-07-03|                 99490|\n",
      "|2020-07-04|                 99301|\n",
      "|2020-07-02|                 99296|\n",
      "|2020-07-05|                 99294|\n",
      "|2020-07-07|                 99213|\n",
      "|2020-07-08|                 99203|\n",
      "|2020-07-10|                 98460|\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_table.groupBy(col(\"date\")).agg(countDistinct(col(\"product_id\")).alias(\"distinct_products_sold\")).orderBy(col(\"distinct_products_sold\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da9163bf-bc8f-48da-8152-8259b2965b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_id: string, product_name: string, price: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9298b215-1ad6-4161-bff8-756bb9588065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: string, product_id: string, seller_id: string, date: string, num_pieces_sold: string, bill_raw_text: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55275d9-345e-4841-a4a3-c107fff38945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[seller_id: string, seller_name: string, daily_target: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sellers_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98749086-8ba0-46f4-b5cf-a450375913bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bddcf6-17f9-43af-bb8c-31d164459e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fac12f3b-ebb1-4008-a539-b7a84eac5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_table = sales_table.join(products_table, \n",
    "                                \"product_id\", \n",
    "                                \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a6b05c-0938-427f-87aa-966e8a82a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_table = joined_table.withColumn(\"revenue\", col(\"num_pieces_sold\") * col(\"price\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0e9a526-da3b-437a-a1fd-8dd2cd4e8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_revenue = (joined_table.groupBy().agg({\"revenue\":\"avg\"}).withColumnRenamed(\"avg(revenue)\", \"average_revenue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8d91ce3-6709-4624-8b92-2ef9d583d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  average_revenue|\n",
      "+-----------------+\n",
      "|3814.589524719816|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "770d2359-a969-4226-8928-03446c6c0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+\n",
      "|seller_id|seller_name|average_contribution|\n",
      "+---------+-----------+--------------------+\n",
      "|        6|   seller_6|0.004781768623614526|\n",
      "|        7|   seller_7|0.002595167082595...|\n",
      "|        5|   seller_5| 0.00421090304838121|\n",
      "|        2|   seller_2|0.006691129824818656|\n",
      "|        1|   seller_1| 0.01963972876684036|\n",
      "|        3|   seller_3| 0.01628585525508843|\n",
      "|        9|   seller_9|0.003838322005051...|\n",
      "|        8|   seller_8|0.009214312305192011|\n",
      "|        4|   seller_4|0.003295439904807...|\n",
      "+---------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Join tables\n",
    "merged_table = sales_table.join(sellers_table, \"seller_id\", \"inner\").join(products_table, \"product_id\", \"inner\")\n",
    "\n",
    "# Step 2: Calculate contribution percentage for each order\n",
    "merged_table = merged_table.withColumn(\"contribution_percentage\", (col(\"num_pieces_sold\") / col(\"daily_target\")) * 100)\n",
    "\n",
    "# Step 3: Calculate average contribution percentage for each seller\n",
    "average_contribution = merged_table.groupBy(\"seller_id\", \"seller_name\").agg(avg(\"contribution_percentage\").alias(\"average_contribution\"))\n",
    "\n",
    "# Display the result\n",
    "average_contribution.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c6cb09a-5069-4af6-8e98-a618753eef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+----+\n",
      "|product_id|seller_id|total_pieces_sold|rank|\n",
      "+----------+---------+-----------------+----+\n",
      "|   1015908|        8|             86.0|   2|\n",
      "|  10277686|        4|             30.0|   2|\n",
      "|  10282881|        7|             30.0|   2|\n",
      "|  10646888|        8|             38.0|   2|\n",
      "|  10669968|        3|             64.0|   2|\n",
      "|  10707485|        7|             11.0|   2|\n",
      "|  10851278|        6|             47.0|   2|\n",
      "|  10989157|        4|              9.0|   2|\n",
      "|  11191322|        7|             22.0|   2|\n",
      "|  11201560|        1|             36.0|   2|\n",
      "|   1121644|        3|             51.0|   2|\n",
      "|  11230312|        6|              2.0|   2|\n",
      "|  11374026|        8|              8.0|   2|\n",
      "|  11408756|        7|             12.0|   2|\n",
      "|   1143343|        7|             32.0|   2|\n",
      "|  11476908|        3|             37.0|   2|\n",
      "|  11650447|        4|             39.0|   2|\n",
      "|  11809907|        6|             45.0|   2|\n",
      "|  11853953|        4|             25.0|   2|\n",
      "|  11918580|        5|             16.0|   2|\n",
      "+----------+---------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+---------+-----------------+----+\n",
      "|product_id|seller_id|total_pieces_sold|rank|\n",
      "+----------+---------+-----------------+----+\n",
      "|  10000047|        9|             29.0|   1|\n",
      "|  10000712|        7|             59.0|   1|\n",
      "|  10000715|        6|             51.0|   1|\n",
      "|  10001485|        3|             12.0|   1|\n",
      "|  10002077|        5|             32.0|   1|\n",
      "|  10002110|        8|             97.0|   1|\n",
      "|  10002770|        7|             57.0|   1|\n",
      "|  10003144|        7|             32.0|   1|\n",
      "|  10004929|        9|             82.0|   1|\n",
      "|  10005243|        6|             98.0|   1|\n",
      "|  10005267|        2|             19.0|   1|\n",
      "|  10005605|        5|              1.0|   1|\n",
      "|  10006252|        2|             40.0|   1|\n",
      "|  10006480|        9|             82.0|   1|\n",
      "|  10007641|        8|             88.0|   1|\n",
      "|   1000879|        5|             20.0|   1|\n",
      "|  10008841|        8|             37.0|   1|\n",
      "|  10008948|        2|             43.0|   1|\n",
      "|  10009135|        3|             72.0|   1|\n",
      "|  10009154|        2|             55.0|   1|\n",
      "+----------+---------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Join tables\n",
    "merged_table = sales_table.join(sellers_table, \"seller_id\", \"inner\").join(products_table, \"product_id\", \"inner\")\n",
    "\n",
    "# Step 2: Calculate the number of pieces sold for each seller and product\n",
    "sales_count = merged_table.groupBy(\"product_id\", \"seller_id\").agg({\"num_pieces_sold\": \"sum\"}).withColumnRenamed(\"sum(num_pieces_sold)\", \"total_pieces_sold\")\n",
    "\n",
    "# Step 3: Use window functions to rank sellers based on sales for each product\n",
    "windowSpec = Window.partitionBy(\"product_id\").orderBy(desc(\"total_pieces_sold\"))\n",
    "\n",
    "sales_count = sales_count.withColumn(\"rank\", dense_rank().over(windowSpec))\n",
    "\n",
    "# Step 4: Filter for the second most and least selling sellers for each product\n",
    "second_most_selling = sales_count.filter(col(\"rank\") == 2)\n",
    "least_selling = sales_count.filter(col(\"rank\") == 1)\n",
    "\n",
    "# Display the results\n",
    "second_most_selling.show()\n",
    "least_selling.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4436adc-cfd5-4e51-bccf-0f6ca31858e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+----+\n",
      "|product_id|seller_id|total_pieces_sold|rank|\n",
      "+----------+---------+-----------------+----+\n",
      "+----------+---------+-----------------+----+\n",
      "\n",
      "+----------+---------+-----------------+----+\n",
      "|product_id|seller_id|total_pieces_sold|rank|\n",
      "+----------+---------+-----------------+----+\n",
      "+----------+---------+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for product_id = 0 in second_most_selling DataFrame\n",
    "filtered_second_most_selling = second_most_selling.filter(col(\"product_id\") == 0)\n",
    "\n",
    "# Filter for product_id = 0 in least_selling DataFrame\n",
    "filtered_least_selling = least_selling.filter(col(\"product_id\") == 0)\n",
    "\n",
    "# Display the filtered results\n",
    "filtered_second_most_selling.show()\n",
    "filtered_least_selling.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ab5965c-980e-4dd2-81ce-ad7cc291dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0e82719-891d-4c28-8b22-8e13f0f0c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|         hashed_bill|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "|  475442|  59216308|        4|2020-07-07|             11|bdfihbvlcxeqioqgm...|0e3869182df64cff0...|\n",
      "|  475460|  64349211|        9|2020-07-05|             93|shwfatjysteuxvjfl...|e496b80b6895ecc77...|\n",
      "|  475745|   6147551|        6|2020-07-07|             33|czhqinijvbhlsljac...|c736acb79325722c4...|\n",
      "|  475748|  18524928|        1|2020-07-09|              3|nfjxfasnrnivfxfdt...|61ab57bccf538f7d5...|\n",
      "|  475765|  44920059|        6|2020-07-08|             77|kqhmsiqtofuowcwfv...|6c570d87e88d70f51...|\n",
      "|  476233|  53991698|        4|2020-07-10|             10|gfsgwwnduxpmevgxc...|449f6dd5d426b81aa...|\n",
      "|  476247|   9083087|        8|2020-07-02|             45|qbvwimpyblobdeeas...|50bffee088018b76f...|\n",
      "|  476342|  56844041|        1|2020-07-07|             28|jentbiirsqyvzmtwu...|7f116f9f0b0acc7cf...|\n",
      "|  476378|   4583362|        5|2020-07-07|             44|kntxdtphezzxiencr...|63b0658613e220197...|\n",
      "|  476436|   3226992|        7|2020-07-09|             66|epdfkexlllyngarnn...|c374e9e44e96969bb...|\n",
      "|  476605|  16478518|        3|2020-07-02|             67|sowhqsofazefdykou...|dd90d18997d099daa...|\n",
      "|  476613|  26742725|        1|2020-07-02|             86|kebqcojololstaQsf...|e74d2e0668581771c...|\n",
      "|  476618|  67843613|        6|2020-07-06|             39|fnszornnjqbunsbdk...|d4672a888ec9ae6f9...|\n",
      "|  476904|  52164566|        3|2020-07-08|              1|qxvyxwulfbacmjscl...|83eda1238bfc723a3...|\n",
      "|  476913|  43047781|        7|2020-07-03|             43|arvjmninostqhxaov...|3d6707b3d7563235f...|\n",
      "|  477268|  64032736|        6|2020-07-10|             44|dzoywhjjsdeqenrvt...|55e7dacbe87018be4...|\n",
      "|  477388|  31763266|        5|2020-07-06|             89|ekyqcbazdleiqpanj...|dade367fe1e5d3814...|\n",
      "|  477481|  29651493|        4|2020-07-04|             18|fkoysmkjxxvweblog...|3e738616e47ef2691...|\n",
      "|  477569|  33046297|        2|2020-07-06|             24|zkywltcuzhomjwcwd...|994ae16277b7168f5...|\n",
      "|  477714|  42874375|        1|2020-07-01|             21|lvosqtykdjangBdnw...|e8e6b7016f4b8fd05...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the UDF function\n",
    "def algo(order_id, bill_text):\n",
    "    order_id = int(order_id)  # Cast order_id to an integer\n",
    "    if order_id % 2 == 0:\n",
    "        # Count the number of capital 'A' in the bill text\n",
    "        count_A = bill_text.upper().count('A')\n",
    "        # Iteratively apply MD5\n",
    "        hashed_result = hashlib.md5(bill_text.encode()).hexdigest()\n",
    "        for _ in range(count_A):\n",
    "            hashed_result = hashlib.md5(hashed_result.encode()).hexdigest()\n",
    "    else:\n",
    "        # Apply SHA256\n",
    "        hashed_result = hashlib.sha256(bill_text.encode()).hexdigest()\n",
    "    \n",
    "    return hashed_result\n",
    "\n",
    "# Register the UDF with Spark session\n",
    "algo_udf = udf(algo, StringType())\n",
    "spark.udf.register(\"algo\", algo_udf)\n",
    "\n",
    "# Apply the UDF to create a new column 'hashed_bill'\n",
    "sales_table = sales_table.withColumn(\"hashed_bill\", algo_udf(col(\"order_id\"), col(\"bill_raw_text\")))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "sales_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e9a80c2-16b5-4ec3-878a-0912355c1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a5b08-df20-494f-8c57-897a2b7b88a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
